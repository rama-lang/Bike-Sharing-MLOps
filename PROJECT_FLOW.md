# ğŸš´ Bike Sharing MLOps - Complete Flow Explanation

## ğŸ“Š System Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERACTION                         â”‚
â”‚                                                                   â”‚
â”‚  Browser â†’ Streamlit UI (Port 8501) â†’ FastAPI (Port 9999)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PREDICTION FLOW                             â”‚
â”‚                                                                   â”‚
â”‚  1. User enters: temp, humidity, hour, season                    â”‚
â”‚  2. Streamlit sends HTTP GET to API                              â”‚
â”‚  3. API loads model (bike_model.pkl)                             â”‚
â”‚  4. Model predicts bike count                                    â”‚
â”‚  5. API saves prediction to PostgreSQL                           â”‚
â”‚  6. API returns result to Streamlit                              â”‚
â”‚  7. User sees predicted bike count                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML PIPELINE FLOW (Airflow)                    â”‚
â”‚                                                                   â”‚
â”‚  DAG: bike_sharing_final_pipeline_v4 (Runs Daily)               â”‚
â”‚                                                                   â”‚
â”‚  Task 1: ingest_data                                             â”‚
â”‚    â†“ Check if data file exists                                   â”‚
â”‚    â†“ Verify file size                                            â”‚
â”‚                                                                   â”‚
â”‚  Task 2: validate_data                                           â”‚
â”‚    â†“ Check for required columns (cnt, temp)                      â”‚
â”‚    â†“ Check for null values                                       â”‚
â”‚    â†“ Fail pipeline if data is bad                                â”‚
â”‚                                                                   â”‚
â”‚  Task 3: train_model                                             â”‚
â”‚    â†“ Load processed data (X_train, y_train)                      â”‚
â”‚    â†“ Train RandomForest model                                    â”‚
â”‚    â†“ Log to MLflow (metrics, parameters)                         â”‚
â”‚    â†“ Register model in MLflow registry                           â”‚
â”‚    â†“ Set "champion" alias to latest version                      â”‚
â”‚    â†“ Save model locally (bike_model.pkl)                         â”‚
â”‚                                                                   â”‚
â”‚  Task 4: test_internal_prediction                                â”‚
â”‚    â†“ Load sample from training data                              â”‚
â”‚    â†“ Make prediction using saved model                           â”‚
â”‚    â†“ Verify model works inside Airflow                           â”‚
â”‚                                                                   â”‚
â”‚  Task 5: call_live_api_tracking                                  â”‚
â”‚    â†“ Call Windows API (host.docker.internal:9999)                â”‚
â”‚    â†“ Send test prediction request                                â”‚
â”‚    â†“ Verify API is serving predictions                           â”‚
â”‚    â†“ Check prediction is saved to database                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MONITORING FLOW (Airflow)                      â”‚
â”‚                                                                   â”‚
â”‚  DAG: model_monitoring_dag (Runs Daily)                          â”‚
â”‚                                                                   â”‚
â”‚  Task 1: generate_report                                         â”‚
â”‚    â†“ Load all predictions from PostgreSQL                        â”‚
â”‚    â†“ Split into reference vs current data                        â”‚
â”‚    â†“ Run Evidently AI drift detection                            â”‚
â”‚    â†“ Generate HTML + JSON reports                                â”‚
â”‚    â†“ Upload report to LocalStack S3                              â”‚
â”‚                                                                   â”‚
â”‚  Task 2: check_for_issues (ShortCircuit)                         â”‚
â”‚    â†“ Parse JSON report                                           â”‚
â”‚    â†“ Check if dataset_drift = True                               â”‚
â”‚    â†“ If NO drift â†’ Stop pipeline (skip next tasks)               â”‚
â”‚    â†“ If DRIFT detected â†’ Continue to alerts                      â”‚
â”‚                                                                   â”‚
â”‚  Task 3: send_slack_alert (Only if drift)                        â”‚
â”‚    â†“ Send message to Slack webhook                               â”‚
â”‚    â†“ Alert team about drift detection                            â”‚
â”‚                                                                   â”‚
â”‚  Task 4: retrain_model (Only if drift)                           â”‚
â”‚    â†“ Load fresh data                                             â”‚
â”‚    â†“ Train new model                                             â”‚
â”‚    â†“ Replace old model file                                      â”‚
â”‚    â†“ API automatically uses new model                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA FLOW                                   â”‚
â”‚                                                                   â”‚
â”‚  Raw Data (bike_sharing_raw.csv)                                 â”‚
â”‚    â†“                                                              â”‚
â”‚  Preprocessing (drop columns, split)                             â”‚
â”‚    â†“                                                              â”‚
â”‚  Processed Data (X_train, X_test, y_train, y_test)              â”‚
â”‚    â†“                                                              â”‚
â”‚  Training (RandomForest)                                         â”‚
â”‚    â†“                                                              â”‚
â”‚  Model File (bike_model.pkl)                                     â”‚
â”‚    â†“                                                              â”‚
â”‚  API loads model                                                 â”‚
â”‚    â†“                                                              â”‚
â”‚  Predictions saved to PostgreSQL                                 â”‚
â”‚    â†“                                                              â”‚
â”‚  Monitoring analyzes predictions                                 â”‚
â”‚    â†“                                                              â”‚
â”‚  Drift detected â†’ Retrain                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete End-to-End Flow

### Step 1: Initial Setup
```
1. docker-compose up -d
   â†“ Starts 10 containers:
   - PostgreSQL (database)
   - LocalStack (S3 simulation)
   - Airflow (webserver + scheduler)
   - MLflow (experiment tracking)
   - Streamlit (frontend)
   - Prometheus (metrics)
   - Grafana (dashboards)

2. python src/api.py
   â†“ Starts FastAPI on Windows
   â†“ Connects to PostgreSQL
   â†“ Loads model file
   â†“ Ready to serve predictions
```

### Step 2: First-Time Training
```
Airflow UI â†’ Trigger "bike_sharing_final_pipeline_v4"
   â†“
1. ingest_data: âœ… Data file found
   â†“
2. validate_data: âœ… Columns present, no nulls
   â†“
3. train_model:
   - Loads X_train.csv, y_train.csv
   - Trains RandomForest (100-200 trees)
   - RMSE calculated
   - Logged to MLflow
   - Model registered as version 1
   - Alias "champion" â†’ version 1
   - Saved to models/bike_model.pkl
   â†“
4. test_internal_prediction: âœ… Model works
   â†“
5. call_live_api_tracking: âœ… API responds
```

### Step 3: Making Predictions
```
User opens Streamlit (localhost:8501)
   â†“
Adjusts sliders: temp=0.8, hr=18, season=2
   â†“
Clicks "Predict Bike Demand"
   â†“
Streamlit â†’ GET http://host.docker.internal:9999/predict?temp=0.8&hr=18&season=2
   â†“
API receives request
   â†“
API loads bike_model.pkl
   â†“
Model predicts: 245 bikes
   â†“
API saves to PostgreSQL:
   INSERT INTO predictions (temp, hr, season, predicted_cnt, timestamp)
   â†“
API returns: {"predicted_bikes": 245}
   â†“
Streamlit displays: "Predicted Bikes Needed: 245"
   â†“
Balloons animation ğŸˆ
```

### Step 4: Continuous Monitoring
```
Next day at midnight â†’ monitoring_dag triggers
   â†“
1. generate_report:
   - SELECT * FROM predictions
   - Split: 50% reference, 50% current
   - Evidently compares distributions
   - Checks: temp, humidity, season, hour, etc.
   - Generates drift_report.html
   - Uploads to S3: bike_report_20260215_120000.html
   â†“
2. check_for_issues:
   - Reads drift_report.json
   - Checks: dataset_drift = True/False
   - If False â†’ Pipeline stops âœ…
   - If True â†’ Continue âš ï¸
   â†“
3. send_slack_alert (if drift):
   - POST to Slack webhook
   - Message: "ğŸš¨ Drift detected! Retraining..."
   â†“
4. retrain_model (if drift):
   - Loads fresh bike_sharing_raw.csv
   - Trains new RandomForest
   - Saves as bike_model.pkl (overwrites old)
   - API automatically uses new model
   - Next prediction uses updated model
```

### Step 5: Viewing Monitoring
```
User opens Streamlit
   â†“
Clicks "View Data Drift Report"
   â†“
Streamlit reads monitoring_report.html
   â†“
Displays embedded report:
   - Feature drift scores
   - Distribution comparisons
   - Statistical tests
   - Drift alerts
```

---

## ğŸ¯ Key Flow Points

### 1. Docker Container Communication
```
Streamlit (container) â†’ API (Windows host)
   Uses: host.docker.internal:9999
   Why: API runs on Windows, not in Docker

Airflow (container) â†’ API (Windows host)
   Uses: host.docker.internal:9999
   Why: Same reason

API (Windows) â†’ PostgreSQL (container)
   Uses: localhost:5432
   Why: PostgreSQL port mapped to host

Airflow (container) â†’ MLflow (container)
   Uses: mlflow_server:5000
   Why: Both in same Docker network
```

### 2. Model Lifecycle
```
Training â†’ MLflow Registry â†’ Local File â†’ API â†’ Predictions
   â†“          â†“                â†“           â†“        â†“
Version 1   Tracked        bike_model   Serves   Logged
Version 2   Compared       .pkl file    Users    to DB
Version 3   Aliased        Updated      Fast     Monitored
```

### 3. Data Lifecycle
```
Raw CSV â†’ Validation â†’ Preprocessing â†’ Training â†’ Model
   â†“          â†“            â†“              â†“         â†“
17K rows   Checks      Split 80/20    RandomForest  PKL
Columns    Quality     X_train        Fit & Score   Saved
Features   Nulls       y_train        Metrics       Versioned
```

### 4. Monitoring Lifecycle
```
Predictions â†’ Database â†’ Drift Detection â†’ Alert â†’ Retrain
   â†“             â†“            â†“              â†“        â†“
Every API    PostgreSQL   Evidently AI   Slack    New Model
call         Logged       Compares       Notifies  Deployed
Timestamped  Queryable    Distributions  Team      Automatic
```

---

## ğŸ”€ Decision Points in Flow

### 1. Data Validation
```
validate_data task:
   IF 'cnt' column missing â†’ FAIL (stop pipeline)
   IF null values in 'cnt' â†’ FAIL (stop pipeline)
   IF 'temp' column missing â†’ FAIL (stop pipeline)
   ELSE â†’ SUCCESS (continue to training)
```

### 2. Drift Detection
```
check_for_issues task:
   IF dataset_drift = False â†’ STOP (skip alerts & retraining)
   IF dataset_drift = True â†’ CONTINUE (alert & retrain)
```

### 3. Model Loading
```
API startup:
   IF bike_model.pkl exists â†’ Load model
   IF bike_model.pkl missing â†’ Return error 0.0
```

---

## âš¡ Performance Flow

### Request Latency
```
User clicks "Predict"
   â†“ 10ms - Streamlit processes
   â†“ 5ms - HTTP request to API
   â†“ 50ms - Model prediction
   â†“ 20ms - Database insert
   â†“ 5ms - HTTP response
   â†“ 10ms - Streamlit renders
Total: ~100ms
```

### Training Time
```
Full pipeline execution:
   ingest_data: 1 second
   validate_data: 2 seconds
   train_model: 30-60 seconds
   test_internal_prediction: 5 seconds
   call_live_api_tracking: 2 seconds
Total: ~1-2 minutes
```

### Monitoring Time
```
Monitoring DAG execution:
   generate_report: 10-30 seconds
   check_for_issues: 1 second
   send_slack_alert: 2 seconds
   retrain_model: 60 seconds (if triggered)
Total: 15-95 seconds (depending on drift)
```

---

## ğŸ”„ Continuous Loop

```
Day 1:
   Train model â†’ Deploy â†’ Serve predictions â†’ Log to DB

Day 2:
   Monitor predictions â†’ No drift â†’ Continue serving

Day 3:
   Monitor predictions â†’ No drift â†’ Continue serving

Day 7:
   Monitor predictions â†’ DRIFT DETECTED!
   â†’ Alert team
   â†’ Retrain model
   â†’ Deploy new model
   â†’ Continue serving (with new model)

Day 8:
   Monitor predictions â†’ No drift â†’ Continue serving
   (cycle repeats)
```

---

## ğŸ“ Where Each Component Fits

### Frontend Layer
- **Streamlit** (app.py): User interface
- **Browser**: User interaction point

### API Layer
- **FastAPI** (api.py): Prediction endpoint
- **Prometheus**: Metrics collection

### ML Layer
- **Training** (train.py): Model creation
- **Prediction** (predict.py): Inference logic
- **Evaluation** (evaluate.py): Performance metrics

### Data Layer
- **PostgreSQL**: Prediction storage
- **LocalStack S3**: Report storage
- **CSV Files**: Training data

### Orchestration Layer
- **Airflow**: Workflow automation
- **DAGs**: Pipeline definitions

### Monitoring Layer
- **Evidently AI**: Drift detection
- **Prometheus**: Metrics
- **Grafana**: Visualization
- **Slack**: Alerts

### Tracking Layer
- **MLflow**: Experiment tracking
- **Model Registry**: Version management

---

## ğŸ¯ Summary: The Complete Flow

1. **User makes prediction** â†’ Streamlit â†’ API â†’ Model â†’ Database
2. **Airflow trains model** â†’ Daily pipeline â†’ MLflow â†’ Model file
3. **Airflow monitors** â†’ Daily check â†’ Drift detection â†’ Conditional retrain
4. **Prometheus tracks** â†’ API metrics â†’ Grafana dashboards
5. **Team gets alerts** â†’ Slack notifications â†’ Take action

**Everything is automated, monitored, and continuously improving!** ğŸš€
